{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps to reproduce experiments in :\n",
    "## **Reproducible evaluation of classification methods in Alzheimer's disease: Framework and application to MRI and PET data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "The original [ADNI](http://adni.loni.usc.edu/), [AIBL](https://aibl.csiro.au/research/neuroimaging/) and [OASIS](http://www.oasis-brains.org/) datasets should be downloaded without further touch (Data we used in our paper was downloaded in October 2016).\n",
    "Fix the paths where your data is stored on your computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export ADNI_PATH=\"~/Aramis/Data/ADNI\"\n",
    "!export AIBL_PATH=\"~/Aramis/Data/AIBL\"\n",
    "!export OASIS_PATH=\"~/Aramis/Data/OASIS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export OUT_PATH=\"~/Aramis/Data/OUTPUT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export WORKING_DIR=\"~/Aramis/Data/tmp/WORKING_DIR\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Convert datasets into BIDS format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!clinica convert adni-to-bids $ADNI_PATH/IMAGES $ADNI_PATH/CLINICAL_DATA $OUT_PATH/ADNI/BIDS -m T1 PET_FDG\n",
    "!clinica convert aibl-to-bids $AIBL_PATH/IMAGES $AIBL_PATH/CLINICAL_DATA $OUT_PATH/AIBL/BIDS\n",
    "!clinica convert oasis-to-bids $OASIS_PATH/IMAGES $OASIS_PATH/CLINICAL_DATA $OUT_PATH/OASIS/BIDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define folders for the next steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "adnimerge = 'PATH/TO/ADNIMERGE.csv'\n",
    "\n",
    "adni_bids = os.path.join(os.environ.get('OUT_PATH'), 'ADNI/BIDS')\n",
    "aibl_bids = os.path.join(os.environ.get('OUT_PATH'), 'AIBL/BIDS')\n",
    "oasis_bids = os.path.join(os.environ.get('OUT_PATH'), 'OASIS/BIDS')\n",
    "\n",
    "adni_tsv_dir = os.path.join(os.environ.get('OUT_PATH'), 'ADNI/TSV')\n",
    "aibl_tsv_dir = os.path.join(os.environ.get('OUT_PATH'), 'AIBL/TSV')\n",
    "oasis_tsv_dir = os.path.join(os.environ.get('OUT_PATH'), 'OASIS/TSV')\n",
    "\n",
    "adni_caps_dir = os.path.join(os.environ.get('OUT_PATH'), 'ADNI/CAPS')\n",
    "aibl_caps_dir = os.path.join(os.environ.get('OUT_PATH'), 'AIBL/CAPS')\n",
    "oasis_caps_dir = os.path.join(os.environ.get('OUT_PATH'), 'OASIS/CAPS')\n",
    "\n",
    "working_dir = os.environ.get('WORKING_DIR')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create the subjects lists\n",
    "Choose the subjects at baseline with available T1 MRI for ADNI, AIBL and OASIS, and with FDG-PET for ADNI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code.subjects_lists.subject_lists import run_subjects_lists\n",
    "\n",
    "### ADNI dataset\n",
    "database = 'ADNI'\n",
    "\n",
    "# For T1\n",
    "subjects_list = 'T1'\n",
    "run_subjects_lists(adni_bids, adni_tsv_dir, database, subjects_list, adnimerge)\n",
    "\n",
    "# For FDG-PET\n",
    "subjects_list = 'PET'\n",
    "run_subjects_lists(adni_bids, adni_tsv_dir, database, subjects_list, adnimerge)\n",
    "\n",
    "\n",
    "### AIBL dataset\n",
    "database = 'AIBL'\n",
    "run_subjects_lists(aibl_bids, aibl_tsv_dir, database)\n",
    "\n",
    "\n",
    "### OASIS dataset\n",
    "database = 'OASIS'\n",
    "run_subjects_lists(oasis_bids, oasis_tsv_dir, database)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create demographic tables information\n",
    "Get demographic information of the different populations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code.subjects_lists.lists_stats import run_lists_stats\n",
    "\n",
    "### ADNI dataset\n",
    "database = 'ADNI'\n",
    "\n",
    "# For T1\n",
    "subjects_list = 'T1'\n",
    "run_lists_stats(adni_bids, adni_tsv_dir, database, subjects_list, adnimerge)\n",
    "\n",
    "# For FDG-PET\n",
    "subjects_list = 'PET'\n",
    "run_lists_stats(adni_bids, adni_tsv_dir, database, subjects_list, adnimerge)\n",
    "\n",
    "\n",
    "### AIBL dataset\n",
    "database = 'AIBL'\n",
    "run_lists_stats(aibl_bids, aibl_tsv_dir, database)\n",
    "\n",
    "\n",
    "### OASIS dataset\n",
    "database = 'OASIS'\n",
    "run_lists_stats(oasis_bids, oasis_tsv_dir, database)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run image processing pipelines\n",
    "Used pipelines are integrated into Clinica software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADNI T1\n",
    "!clinica run t1-spm-full-prep $OUT_PATH/ADNI/BIDS $OUT_PATH/ADNI/CAPS/ ADNIbl -tsv /SUBJECTS_DIR/subjects_T1_PET.tsv -wd $WORKING_DIR -np 8\n",
    "### ADNI FDG-PET\n",
    "!clinica run pet-preprocess-volume $OUT_PATH/ADNI/BIDS $OUT_PATH/ADNI/CAPS/ ADNIbl -tsv $OUT_PATH/ADNI/TSV/subjects_T1_PET.tsv -wd $WORKING_DIR -np 8\n",
    "\n",
    "### AIBL T1\n",
    "!clinica run t1-spm-full-prep $OUT_PATH/AIBL/BIDS $OUT_PATH/AIBL/CAPS/ AIBLbl -tsv $OUT_PATH/AIBL/TSV/subjects_T1.tsv -wd $WORKING_DIR -np 8\n",
    "### OASIS T1\n",
    "!clinica run t1-spm-full-prep $OUT_PATH/OASIS/BIDS $OUT_PATH/OASIS/CAPS/ OASISbl -tsv $OUT_PATH/OASIS/TSV/subjects_T1.tsv -wd $WORKING_DIR -np 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AIBL and OASIS are registered into ADNI template to later test ADNI trained classifiers on AIBL and OASIS\n",
    "\n",
    "###AIBL\n",
    "!clinica run t1-spm-dartel-existing-template $OUT_PATH/AIBL/BIDS $OUT_PATH/AIBL/CAPS/ ADNIbl -tsv $OUT_PATH/AIBL/TSV/subjects_T1.tsv -wd $WORKING_DIR -np 8\n",
    "!clinica run t1-spm-dartel2mni $OUT_PATH/AIBL/BIDS $OUT_PATH/AIBL/CAPS/ AIBLbl -tsv $OUT_PATH/AIBL/TSV/subjects_T1.tsv -wd $WORKING_DIR -np 8\n",
    "\n",
    "###OASIS\n",
    "!clinica run t1-spm-dartel-existing-template $OUT_PATH/OASIS/BIDS $OUT_PATH/OASIS/CAPS/ ADNIbl -tsv $OUT_PATH/OASIS/SUBJECTS_DIR/subjects_T1.tsv -wd $WORKING_DIR -np 8\n",
    "!clinica run t1-spm-dartel2mni $OUT_PATH/OASIS/BIDS $OUT_PATH/OASIS/CAPS/ OASISbl -tsv $OUT_PATH/OASIS/SUBJECTS_DIR/subjects_T1.tsv -wd $WORKING_DIR -np 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run the classification tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We present in more detail the experiments where main classifications are performed\n",
    "\n",
    "### Classification results using T1-weighted MRI and FDG-PET images from ADNI dataset\n",
    "\n",
    "(from `1-main_classifications/ADNI_run_classifications.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import clinica.pipeline.machine_learning.ml_workflows as ml_wf\n",
    "\n",
    "n_iterations = 250\n",
    "n_threads = 8\n",
    "\n",
    "caps_dir = '/ADNI/CAPS'\n",
    "output_dir = '/ADNI/CLASSIFICATION/OUTPUTS'\n",
    "\n",
    "group_id = 'ADNIbl'\n",
    "image_types = ['T1', 'fdg']\n",
    "tasks_dir = '/ADNI/lists_by_task'\n",
    "tasks = [('CN', 'AD'),\n",
    "         ('CN', 'MCI'),\n",
    "         ('CN', 'pMCI'),\n",
    "         ('sMCI', 'pMCI'),\n",
    "         ('CN-', 'AD+'),\n",
    "         ('CN-', 'MCI+'),\n",
    "         ('CN-', 'pMCI+'),\n",
    "         ('MCI-', 'MCI+'),\n",
    "         ('sMCI+', 'pMCI+')]\n",
    "\n",
    "smoothing = [0, 4, 8, 12]\n",
    "atlases = ['AAL2', 'LPBA40', 'Neuromorphometrics', 'AICHA', 'Hammers']\n",
    "pvcs = [None, 'rbv']\n",
    "rb_classifiers = {'linear_svm': ml_wf.RB_RepHoldOut_DualSVM,\n",
    "                  'logistic_regression': ml_wf.RB_RepHoldOut_LogisticRegression,\n",
    "                  'random_forest': ml_wf.RB_RepHoldOut_RandomForest}\n",
    "\n",
    "###################################\n",
    "### Voxel based classifications ###\n",
    "###################################\n",
    "\n",
    "for image_type in image_types:\n",
    "    for fwhm in smoothing:\n",
    "        for task in tasks:\n",
    "            subjects_visits_tsv = path.join(tasks_dir, '%s_vs_%s_subjects_sessions.tsv' % (task[0], task[1]))\n",
    "            diagnoses_tsv = path.join(tasks_dir, '%s_vs_%s_diagnoses.tsv' % (task[0], task[1]))\n",
    "            for pvc in pvcs:\n",
    "                if image_type == 'T1':\n",
    "                    if pvc is None:\n",
    "                        classification_dir = path.join(output_dir, image_type, 'voxel_based',\n",
    "                                                       'smooothing-%s' % fwhm, 'linear_svm',\n",
    "                                                       '%s_vs_%s' % (task[0], task[1]))\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    classification_dir = path.join(output_dir, image_type, 'voxel_based', 'pvc-%s' % pvc,\n",
    "                                                   'smooothing-%s' % fwhm, 'linear_svm',\n",
    "                                                   '%s_vs_%s' % (task[0], task[1]))\n",
    "                if not path.exists(classification_dir):\n",
    "                    os.makedirs(classification_dir)\n",
    "\n",
    "                print \"Running %s\" % classification_dir\n",
    "                wf = ml_wf.VB_RepHoldOut_DualSVM(caps_dir, subjects_visits_tsv, diagnoses_tsv, group_id, image_type,\n",
    "                                                 classification_dir, fwhm=fwhm, pvc=pvc, n_iterations=n_iterations,\n",
    "                                                 n_threads=n_threads)\n",
    "                wf.run()\n",
    "\n",
    "####################################\n",
    "### Region based classifications ###\n",
    "####################################\n",
    "\n",
    "for image_type in image_types:\n",
    "    for atlas in atlases:\n",
    "        for task in tasks:\n",
    "            subjects_visits_tsv = path.join(tasks_dir, '%s_vs_%s_subjects_sessions.tsv' % (task[0], task[1]))\n",
    "            diagnoses_tsv = path.join(tasks_dir, '%s_vs_%s_diagnoses.tsv' % (task[0], task[1]))\n",
    "            for classifier in rb_classifiers:\n",
    "                ml_class = rb_classifiers[classifier]\n",
    "                for pvc in pvcs:\n",
    "                    if image_type == 'T1':\n",
    "                        if pvc is None:\n",
    "                            classification_dir = path.join(output_dir, image_type, 'region_based',\n",
    "                                                           'atlas-%s' % atlas, classifier,\n",
    "                                                           '%s_vs_%s' % (task[0], task[1]))\n",
    "                        else:\n",
    "                            continue\n",
    "                    else:\n",
    "                        classification_dir = path.join(output_dir, image_type, 'region_based', 'pvc-%s' % pvc,\n",
    "                                                       'atlas-%s' % atlas, classifier,\n",
    "                                                       '%s_vs_%s' % (task[0], task[1]))\n",
    "                    if not path.exists(classification_dir):\n",
    "                        os.makedirs(classification_dir)\n",
    "\n",
    "                    print \"Running %s\" % classification_dir\n",
    "                    wf = ml_class(caps_dir, subjects_visits_tsv, diagnoses_tsv, group_id, image_type, atlas,\n",
    "                                  classification_dir, pvc=pvc, n_iterations=n_iterations, n_threads=n_threads)\n",
    "                    wf.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification results using T1-weighted MRI from AIBL dataset\n",
    "\n",
    "(from `1-main_classifications/AIBL_run_classifications.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import clinica.pipeline.machine_learning.ml_workflows as ml_wf\n",
    "\n",
    "n_iterations = 250\n",
    "n_threads = 8\n",
    "\n",
    "caps_dir = '/AIBL/CAPS'\n",
    "output_dir = '/AIBL/CLASSIFICATION/OUTPUTS'\n",
    "\n",
    "group_id = 'AIBLbl'\n",
    "image_types = ['T1']\n",
    "tasks_dir = '/AIBL/lists_by_task'\n",
    "tasks = [('CN', 'AD'),\n",
    "         ('CN', 'MCI'),\n",
    "         ('sMCI', 'pMCI')]\n",
    "\n",
    "smoothing = [0, 4, 8, 12]\n",
    "atlases = ['AAL2', 'LPBA40', 'Neuromorphometrics', 'AICHA', 'Hammers']\n",
    "pvcs = [None, 'rbv']\n",
    "rb_classifiers = {'linear_svm': ml_wf.RB_RepHoldOut_DualSVM,\n",
    "                  'logistic_regression': ml_wf.RB_RepHoldOut_LogisticRegression,\n",
    "                  'random_forest': ml_wf.RB_RepHoldOut_RandomForest}\n",
    "\n",
    "###################################\n",
    "### Voxel based classifications ###\n",
    "###################################\n",
    "\n",
    "for image_type in image_types:\n",
    "    for fwhm in smoothing:\n",
    "        for task in tasks:\n",
    "            subjects_visits_tsv = path.join(tasks_dir, '%s_vs_%s_subjects_sessions.tsv' % (task[0], task[1]))\n",
    "            diagnoses_tsv = path.join(tasks_dir, '%s_vs_%s_diagnoses.tsv' % (task[0], task[1]))\n",
    "            for pvc in pvcs:\n",
    "                if image_type == 'T1':\n",
    "                    if pvc is None:\n",
    "                        classification_dir = path.join(output_dir, image_type, 'voxel_based',\n",
    "                                                       'smooothing-%s' % fwhm, 'linear_svm',\n",
    "                                                       '%s_vs_%s' % (task[0], task[1]))\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    classification_dir = path.join(output_dir, image_type, 'voxel_based', 'pvc-%s' % pvc,\n",
    "                                                   'smooothing-%s' % fwhm, 'linear_svm',\n",
    "                                                   '%s_vs_%s' % (task[0], task[1]))\n",
    "                if not path.exists(classification_dir):\n",
    "                    os.makedirs(classification_dir)\n",
    "\n",
    "                print \"Running %s\" % classification_dir\n",
    "                wf = ml_wf.VB_RepHoldOut_DualSVM(caps_dir, subjects_visits_tsv, diagnoses_tsv, group_id, image_type,\n",
    "                                                 classification_dir, fwhm=fwhm, pvc=pvc, n_iterations=n_iterations,\n",
    "                                                 n_threads=n_threads)\n",
    "                wf.run()\n",
    "\n",
    "####################################\n",
    "### Region based classifications ###\n",
    "####################################\n",
    "\n",
    "for image_type in image_types:\n",
    "    for atlas in atlases:\n",
    "        for task in tasks:\n",
    "            subjects_visits_tsv = path.join(tasks_dir, '%s_vs_%s_subjects_sessions.tsv' % (task[0], task[1]))\n",
    "            diagnoses_tsv = path.join(tasks_dir, '%s_vs_%s_diagnoses.tsv' % (task[0], task[1]))\n",
    "\n",
    "            for classifier in rb_classifiers:\n",
    "                ml_class = rb_classifiers[classifier]\n",
    "\n",
    "                for pvc in pvcs:\n",
    "                    if image_type == 'T1':\n",
    "                        if pvc is None:\n",
    "                            classification_dir = path.join(output_dir, image_type, 'region_based',\n",
    "                                                           'atlas-%s' % atlas, classifier,\n",
    "                                                           '%s_vs_%s' % (task[0], task[1]))\n",
    "                        else:\n",
    "                            continue\n",
    "                    else:\n",
    "                        classification_dir = path.join(output_dir, image_type, 'region_based', 'pvc-%s' % pvc,\n",
    "                                                       'atlas-%s' % atlas, classifier,\n",
    "                                                       '%s_vs_%s' % (task[0], task[1]))\n",
    "\n",
    "                    if not path.exists(classification_dir):\n",
    "                        os.makedirs(classification_dir)\n",
    "\n",
    "                    print \"Running %s\" % classification_dir\n",
    "                    wf = ml_class(caps_dir, subjects_visits_tsv, diagnoses_tsv, group_id, image_type, atlas,\n",
    "                                  classification_dir, pvc=pvc, n_iterations=n_iterations, n_threads=n_threads)\n",
    "                    wf.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification results using T1-weighted MRI from OASIS dataset\n",
    "\n",
    "(from `1-main_classifications/OASIS_run_classifications.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import clinica.pipeline.machine_learning.ml_workflows as ml_wf\n",
    "\n",
    "n_iterations = 250\n",
    "n_threads = 8\n",
    "\n",
    "caps_dir = '/OASIS/CAPS'\n",
    "output_dir = '/OASIS/CLASSIFICATION/OUTPUTS'\n",
    "\n",
    "group_id = 'OASISbl'\n",
    "]image_types = ['T1'\n",
    "tasks_dir = '/teams/ARAMIS/PROJECTS/simona.bottani/ADML_paper/OASIS/lists_by_task'\n",
    "tasks = [('CN', 'AD')]\n",
    "\n",
    "smoothing = [0, 4, 8, 12]\n",
    "atlases = ['AAL2', 'LPBA40', 'Neuromorphometrics', 'AICHA', 'Hammers']\n",
    "pvcs = [None, 'rbv']\n",
    "rb_classifiers = {'linear_svm': ml_wf.RB_RepHoldOut_DualSVM,\n",
    "                  'logistic_regression': ml_wf.RB_RepHoldOut_LogisticRegression,\n",
    "                  'random_forest': ml_wf.RB_RepHoldOut_RandomForest}\n",
    "\n",
    "###################################\n",
    "### Voxel based classifications ###\n",
    "###################################\n",
    "\n",
    "for image_type in image_types:\n",
    "    for fwhm in smoothing:\n",
    "        for task in tasks:\n",
    "            subjects_visits_tsv = path.join(tasks_dir, '%s_vs_%s_subjects_sessions.tsv' % (task[0], task[1]))\n",
    "            diagnoses_tsv = path.join(tasks_dir, '%s_vs_%s_diagnoses.tsv' % (task[0], task[1]))\n",
    "            for pvc in pvcs:\n",
    "                if image_type == 'T1':\n",
    "                    if pvc is None:\n",
    "                        classification_dir = path.join(output_dir, image_type, 'voxel_based',\n",
    "                                                       'smooothing-%s' % fwhm, 'linear_svm',\n",
    "                                                       '%s_vs_%s' % (task[0], task[1]))\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    classification_dir = path.join(output_dir, image_type, 'voxel_based', 'pvc-%s' % pvc,\n",
    "                                                   'smooothing-%s' % fwhm, 'linear_svm',\n",
    "                                                   '%s_vs_%s' % (task[0], task[1]))\n",
    "                if not path.exists(classification_dir):\n",
    "                    os.makedirs(classification_dir)\n",
    "\n",
    "                print \"Running %s\" % classification_dir\n",
    "                wf = ml_wf.VB_RepHoldOut_DualSVM(caps_dir, subjects_visits_tsv, diagnoses_tsv, group_id, image_type,\n",
    "                                                 classification_dir, fwhm=fwhm, pvc=pvc, n_iterations=n_iterations,\n",
    "                                                 n_threads=n_threads)\n",
    "                wf.run()\n",
    "\n",
    "####################################\n",
    "### Region based classifications ###\n",
    "####################################\n",
    "\n",
    "for image_type in image_types:\n",
    "    for atlas in atlases:\n",
    "        for task in tasks:\n",
    "            subjects_visits_tsv = path.join(tasks_dir, '%s_vs_%s_subjects_sessions.tsv' % (task[0], task[1]))\n",
    "            diagnoses_tsv = path.join(tasks_dir, '%s_vs_%s_diagnoses.tsv' % (task[0], task[1]))\n",
    "            for classifier in rb_classifiers:\n",
    "                ml_class = rb_classifiers[classifier]\n",
    "                for pvc in pvcs:\n",
    "                    if image_type == 'T1':\n",
    "                        if pvc is None:\n",
    "                            classification_dir = path.join(output_dir, image_type, 'region_based',\n",
    "                                                           'atlas-%s' % atlas, classifier,\n",
    "                                                           '%s_vs_%s' % (task[0], task[1]))\n",
    "                        else:\n",
    "                            continue\n",
    "                    else:\n",
    "                        classification_dir = path.join(output_dir, image_type, 'region_based', 'pvc-%s' % pvc,\n",
    "                                                       'atlas-%s' % atlas, classifier,\n",
    "                                                       '%s_vs_%s' % (task[0], task[1]))\n",
    "                    if not path.exists(classification_dir):\n",
    "                        os.makedirs(classification_dir)\n",
    "\n",
    "                    print \"Running %s\" % classification_dir\n",
    "                    wf = ml_class(caps_dir, subjects_visits_tsv, diagnoses_tsv, group_id, image_type, atlas,\n",
    "                                  classification_dir, pvc=pvc, n_iterations=n_iterations, n_threads=n_threads)\n",
    "                    wf.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other more specific classification tasks can be run directly from the `Code` directory:\n",
    "\n",
    "#### Comparison of classification results using T1-weighted MRI with different magnetic field strenghts from ADNI dataset\n",
    "\n",
    "```\n",
    "python 2-magnetic_field_strength/get_accuracies.py\n",
    "```\n",
    "\n",
    "#### Effect of class imbalance on classification results using T1-weighted MRI from ADNI and AIBL datasets\n",
    "\n",
    "```\n",
    "python 3-class_imbalance/subjects_ADNI.py\n",
    "python 3-class_imbalance/subjects_AIBL.py\n",
    "python 3-class_imbalance/1-ADNI_balanced_voxel_based.py\n",
    "python 3-class_imbalance/2-ADNI_balanced_region_based.py\n",
    "python 3-class_imbalance/3-AIBL_CN_AD_balanced.py\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "#### Effect of dataset on classification results and generalization tests using T1-weighted MRI from ADNI, AIBL and OASIS datasets\n",
    "\n",
    "Generating subjects lists with the specific number of subjects for all the upcoming tasks:\n",
    "```\n",
    "python 4-influence_of_dataset/subjects.py\n",
    "```\n",
    "\n",
    "Obtaining dataset specific classification results with the same number of subjects:\n",
    "```\n",
    "python 4-influence_of_dataset/1-subset_70_subj/ADNI_run_classification_70_49.py\n",
    "python 4-influence_of_dataset/1-subset_70_subj/AIBL_run_classification_70.py\n",
    "python 4-influence_of_dataset/1-subset_70_subj/OASIS_run_classification_70.py\n",
    "```\n",
    "\n",
    "Generalization test of ADNI trained classifier on AIBL and OASIS (using all available subjects):\n",
    "```\n",
    "python 4-influence_of_dataset/2-full_ADNI_on_full_datasets/ADNI_on_AIBL_run_classifications_region.py\n",
    "python 4-influence_of_dataset/2-full_ADNI_on_full_datasets/ADNI_on_AIBL_run_classifications_voxel.py\n",
    "python 4-influence_of_dataset/2-full_ADNI_on_full_datasets/ADNI_on_OASIS_run_classifications_region.py\n",
    "python 4-influence_of_dataset/2-full_ADNI_on_full_datasets/ADNI_on_OASIS_run_classifications_voxel.py\n",
    "```\n",
    "\n",
    "Generalization test of ADNI trained classifier on AIBL and OASIS (using same number of subjects):\n",
    "```\n",
    "python 4-influence_of_dataset/3-49s_ADNI_on_70s_datasets/ADNI_on_AIBL_run_classifications_region.py\n",
    "python 4-influence_of_dataset/3-49s_ADNI_on_70s_datasets/ADNI_on_AIBL_run_classifications_voxel.py\n",
    "python 4-influence_of_dataset/3-49s_ADNI_on_70s_datasets/ADNI_on_OASIS_run_classifications_region.py\n",
    "python 4-influence_of_dataset/3-49s_ADNI_on_70s_datasets/ADNI_on_OASIS_run_classifications_voxel.py\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
